Here is AWS-focused code based on your YAML. It provisions a standard SQS queue with a DLQ in Terraform and provides Python code (Boto3) to interact with the queue (send, receive, delete, change visibility, and update the retry/WIP policy).

Important notes
- Substrates in your YAML include AWS, Azure, GCP, OCI. The following code is specifically for AWS SQS (as requested).
- The DLQ and main queue use a redrive policy with maxReceiveCount equal to 5 (number_of_retries).
- The queue size limit is set to the MaximumMessageSize of 262144 bytes (256 KB).
- Visibility timeout is set to 30 seconds.
- Tags reflect the provided metadata (project: cloud-abstractor, env: dev).

Terraform: AWS SQS standard queue with DLQ
- main.tf

provider "aws" {
  region = var.aws_region
}

variable "aws_region" {
  description = "AWS region to create queues in"
  type        = string
  default     = "us-east-1"
}

# Dead-letter queue
resource "aws_sqs_queue" "dlq" {
  name                 = "myDLQ"
  max_message_size     = 262144
  message_retention_seconds = 1209600

  # Optional: you may set a different visibility_timeout or retention for the DLQ if desired
  tags = {
    Project     = "cloud-abstractor"
    Environment = "dev"
  }
}

# Primary queue
resource "aws_sqs_queue" "queue" {
  name                    = "myQueue"
  max_message_size        = 262144
  visibility_timeout_seconds = 30

  # Attach DLQ via redrive policy
  redrive_policy = jsonencode({
    deadLetterTargetArn = aws_sqs_queue.dlq.arn
    maxReceiveCount     = 5
  })

  tags = {
    Project     = "cloud-abstractor"
    Environment = "dev"
  }
}

Outputs (optional)
- queue_url and queue_arn for convenience

output "queue_url" {
  value = aws_sqs_queue.queue.id
}

output "queue_arn" {
  value = aws_sqs_queue.queue.arn
}

output "dlq_url" {
  value = aws_sqs_queue.dlq.id
}

How to use Terraform
- Save the above as main.tf
- Run:
  - terraform init
  - terraform apply
- Terraform will create:
  - DLQ: myDLQ
  - Main queue: myQueue with max_message_size 262144, visibility_timeout 30s, and a RedrivePolicy pointing to myDLQ with maxReceiveCount 5.

Python: AWS SQS interactions using Boto3
- sqs_interact.py

import json
import boto3

class SQSManager:
    def __init__(self, region_name="us-east-1", queue_name="myQueue", dlq_name="myDLQ"):
        self.sqs = boto3.client("sqs", region_name=region_name)
        self.queue_name = queue_name
        self.dlq_name = dlq_name

        self.queue_url = self._get_queue_url(queue_name)
        self.dlq_url = self._get_queue_url(dlq_name)

        self.queue_arn = self._get_queue_attribute(self.queue_url, "QueueArn")
        self.dlq_arn = self._get_queue_attribute(self.dlq_url, "QueueArn")

    def _get_queue_url(self, name):
        resp = self.sqs.get_queue_url(QueueName=name)
        return resp["QueueUrl"]

    def _get_queue_attribute(self, queue_url, attribute_name):
        resp = self.sqs.get_queue_attributes(
            QueueUrl=queue_url,
            AttributeNames=[attribute_name]
        )
        return resp["Attributes"][attribute_name]

    # Add a message to the main queue
    def send_message(self, message_body, delay_seconds=0, message_attributes=None):
        params = {
            "QueueUrl": self.queue_url,
            "MessageBody": str(message_body),
            "DelaySeconds": int(delay_seconds)
        }
        if message_attributes:
            params["MessageAttributes"] = message_attributes
        resp = self.sqs.send_message(**params)
        return resp

    # Retrieve messages from the main queue
    def receive_messages(self, max_number=1, wait_time_seconds=0, visibility_timeout=None):
        params = {
            "QueueUrl": self.queue_url,
            "MaxNumberOfMessages": int(max_number),
            "WaitTimeSeconds": int(wait_time_seconds)
        }
        if visibility_timeout is not None:
            params["VisibilityTimeout"] = int(visibility_timeout)
        resp = self.sqs.receive_message(**params)
        return resp.get("Messages", [])

    # Delete a received message using its receipt handle
    def delete_message(self, receipt_handle):
        self.sqs.delete_message(QueueUrl=self.queue_url, ReceiptHandle=receipt_handle)

    # Change visibility timeout for a in-flight message
    def change_visibility_timeout(self, receipt_handle, visibility_timeout):
        self.sqs.change_message_visibility(
            QueueUrl=self.queue_url,
            ReceiptHandle=receipt_handle,
            VisibilityTimeout=int(visibility_timeout)
        )

    # Update the redrive policy (e.g., number_of_retries)
    def set_retry_count(self, max_receive_count):
        policy = {
            "deadLetterTargetArn": self.dlq_arn,
            "maxReceiveCount": str(max_receive_count)
        }
        self.sqs.set_queue_attributes(
            QueueUrl=self.queue_url,
            Attributes={
                "RedrivePolicy": json.dumps(policy)
            }
        )

# Example usage
if __name__ == "__main__":
    # Assumes AWS credentials are configured (environment or AWS config)
    region = "us-east-1"  # adjust as needed
    queue_name = "myQueue"
    dlq_name = "myDLQ"

    manager = SQSManager(region_name=region, queue_name=queue_name, dlq_name=dlq_name)

    # Send a message
    send_resp = manager.send_message("Hello from Terraform + Python!")
    print("Sent message, MessageId:", send_resp.get("MessageId"))

    # Receive a message
    messages = manager.receive_messages(max_number=1, wait_time_seconds=5)
    if messages:
        msg = messages[0]
        body = msg.get("Body")
        receipt_handle = msg.get("ReceiptHandle")
        print("Received message body:", body)

        # Delete the message after processing
        manager.delete_message(receipt_handle)
        print("Message deleted.")
    else:
        print("No messages received.")

    # Change visibility timeout example (if you need more time to process)
    # manager.change_visibility_timeout(receipt_handle, visibility_timeout=60)

    # Update retries (maxReceiveCount) to, for example, 5
    manager.set_retry_count(5)
    print("Retry count updated to 5 for the main queue.")

Notes and tips
- If you want to switch to a FIFO queue, you would adjust the Terraform configuration to create a FIFO queue (name ending with .fifo, set content_based_deduplication accordingly, and update any producer/consumer logic in Python to handle MessageGroupId and deduplication as needed).
- The Python sample uses the queue names directly (myQueue and myDLQ). If you deploy in a non-default region, ensure the region_name parameter matches your Terraform deployment region.
- The YAML’s metadata field is represented in Terraform by the tags Project=cloud-abstractor and Environment=dev. You can extend tags as needed.

If you’d like, I can tailor the Terraform and Python code to:
- Use dynamic inputs (variables) for region, names, and retry counts.
- Add IAM policies for the necessary SQS permissions.
- Include error handling and retry logic in Python.